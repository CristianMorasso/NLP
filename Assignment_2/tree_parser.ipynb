{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignement 2\n",
    "\n",
    "The assignment consists in the development, in NLTK, OpenNLP, SketchEngine or GATE/Annie a pipeline that, starting from a text in input, in a given language (English, French, German and Italian are admissible) outputs the syntactic tree of the sentence itself, intended as a tree with root in S for sentence, and leaves on the tokens labelled with a single Part-of-speech. The generation of the tree can pass through one of the following models:\n",
    "\n",
    "### 1) PURE SYMBOLIC\n",
    "The tree is generated by a LR analysis with CF LL2 grammar as a base. Candidates can assume the following:\n",
    "<ol>\n",
    "<li>Adjectives in English and German shall be only prefixed to nouns, whilst in French and Italian are only suffixed; </li>\n",
    "<li>Verbs are all at present tense;</li>\n",
    "<li>No pronouns are admitted;</li>\n",
    "<li>Only one adverb is admitted, always post-poned with respect to the verb (independently of the language, and the type of adverb);</li>\n",
    "</ol>\n",
    "\n",
    "Overall the point above map a system that could be devised in regular expressions, but a Context-free grammar would be simpler to     \n",
    "define. Candidate can either define a system by themselves or use a syntactic tree generation system that can be found on GitHub. \n",
    "Same happens for POS-tagging, where some of the above mentioned systems can be customized by existing techniques that are available\n",
    "in several fashions (including a pre-defined NLTK and OpenNLP libraries for POS-tagging and a module in GATE for the same purpose. Ambiguity \n",
    "should be blocked onto first admissible tree.\n",
    "\n",
    "### 2) PURE ML.\n",
    "Candidates can develop a PLM with one-step Markov chains to forecast the following token, and used to generate the forecast of the\n",
    "POS tags to be attributed. In this case the PLM can be generated starting with a Corpus, that could be obtained online, for instance by \n",
    "using the Wikipedia access API, or other available free repos (including those available with SketchEngine. In this approach, candidates should\n",
    "never use the forecasting to approach the determination of outcomes (for this would be identical purpose of distinguishing EN/non ENG (and\n",
    "then IT/non IT, FR/not FR or DE/not DE) but only to identify the POS model in a sequence. In this case, the candidate should output the most\n",
    "likely POS tagging, without associating the sequence to a tree in a direct fashion.\n",
    "\n",
    "Candidates are free to employ PURE ML approach to simplify, or pre-process the text in order to improve the performance of a PURE SYMBOLIC approach while generating a mixed model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This software uses the first approch\n",
    "\n",
    "The user can select the language as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As first we define some grammar productions to make grammar and pos tagger on the same Non Terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_to_nltk_grammar = \"\"\"\n",
    "N -> NOUN\n",
    "V -> VERB\n",
    "P -> ADP\n",
    "\"\"\"\n",
    "nlp = None\n",
    "sentences = []\n",
    "base_grammar = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SetUp info\n",
    "For each language setup:\n",
    "<ul>\n",
    "    <li>Load pos tagger from spacy.</li>\n",
    "    <li>Some test sentences</li>\n",
    "    <li>The base language grammar according to the specifics, then we apply the other grammar that we define before</li>\n",
    "</ul>\n",
    "\n",
    "Note: Not all sentences will work "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENGLISH SETUP\n",
    "\n",
    "Note: English and German adjectives are prefixed to nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_english():\n",
    "    # LOAD ENGLISH POS TAGGER\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # ENGLISH TEST SENTENCES \n",
    "    sentences = [\"The ginger cat runs fast.\",\n",
    "    \"The gray cat is black.\",\n",
    "    \"The cat is running away\",\n",
    "    \"I love cats.\",\n",
    "    \"Little cats are great.\",\n",
    "    \"Fat cats are awesome.\"]\n",
    "\n",
    "    # ENGLISH SPECIFIC GRAMMAR  \n",
    "    base_grammar= \"\"\"\n",
    "    S -> NP VP PUNCT | NP VP | PUNCT NP VP PUNCT\n",
    "    NP -> NUM ADJ N | N | ADJP NP  | DET NP \n",
    "    VP -> VP NP | V | VP ADVP | VP SCONJ VP | AUX VP | VP PUNCT | AUX ADJP| AUX ADV \n",
    "    ADVP -> ADV \n",
    "    ADJP -> ADJ | ADJ ADJP\n",
    "    PP -> P NP\n",
    "    \"\"\" + spacy_to_nltk_grammar\n",
    "    print(\"English setup done\")\n",
    "    return nlp, sentences, base_grammar\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GERMAN SETUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_german():\n",
    "    # LOAD GERMAN POS TAGGER\n",
    "    nlp = spacy.load(\"de_core_news_sm\") \n",
    "\n",
    "    # GERMAN TEST SENTENCES \n",
    "    sentences = [\"Die rote Katze rennt schnell.\",\n",
    "    \"Die graue Katze ist schwarz.\",\n",
    "    \"Die Katze läuft weg\",\n",
    "    \"Ich liebe Katzen.\",\n",
    "    \"Kleine Katzen sind toll.\",\n",
    "    \"Fette Katzen sind großartig.\"]\n",
    "\n",
    "    # GERMAN GRAMMAR  \n",
    "    base_grammar= \"\"\"\n",
    "    S -> NP VP PUNCT | NP VP | PUNCT NP VP PUNCT\n",
    "    NP -> NUM ADJ N | N | ADJP NP  | DET NP \n",
    "    VP -> VP NP | V | VP ADVP | VP SCONJ VP | AUX VP | VP PUNCT | AUX ADJP| AUX ADV \n",
    "    ADVP -> ADV \n",
    "    ADJP -> ADJ | ADJ ADJP\n",
    "    PP -> P NP\n",
    "    \"\"\" + spacy_to_nltk_grammar\n",
    "    print(\"German setup done\")\n",
    "    return nlp, sentences, base_grammar\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITALIAN SETUP\n",
    "\n",
    "Note: Italian and French adjectives are suffixed to nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_italian():\n",
    "    # LOAD ITALIAN POS TAGGER\n",
    "    nlp = spacy.load(\"it_core_news_sm\") \n",
    "\n",
    "    # ITALIAN TEST SENTENCES \n",
    "    sentences = [\"Il gatto rosso corre velocemente.\",\n",
    "    \"Il gatto grigio è nero.\",\n",
    "    \"Il gatto sta correndo via\",\n",
    "    \"Adoro i gatti.\",\n",
    "    \"I gatti piccoli sono fantastici.\",\n",
    "    \"I gatti grassi sono fantastici.\"]\n",
    "\n",
    "    # ITALIAN GRAMMAR  \n",
    "    base_grammar= \"\"\"\n",
    "    S -> NP VP PUNCT | NP VP | PUNCT NP VP PUNCT\n",
    "    NP -> NUM N ADJ | N | NP ADJP | DET NP \n",
    "    VP -> VP NP | V | VP ADVP | VP SCONJ VP | AUX VP | VP PUNCT | AUX ADJP| AUX ADV \n",
    "    ADVP -> ADV \n",
    "    ADJP -> ADJ | ADJ ADJP\n",
    "    PP -> P NP\n",
    "    \"\"\" + spacy_to_nltk_grammar\n",
    "    print(\"Italian setup done\")\n",
    "    return nlp, sentences, base_grammar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRENCH SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_french():\n",
    "    \n",
    "    # LOAD FRENCH POS TAGGER\n",
    "    nlp = spacy.load(\"fr_core_news_sm\") \n",
    "\n",
    "    # FRENCH TEST SENTENCES \n",
    "    sentences = [\"Le chat roux court vite.\",\n",
    "    \"Le chat gris est noir.\",\n",
    "    \"Le chat s'enfuit\",\n",
    "    \"J'aime les chats.\",\n",
    "    \"Les petits chats sont géniaux.\",\n",
    "    \"Les gros chats sont géniaux.\"]\n",
    "\n",
    "    # FRENCH GRAMMAR  \n",
    "    base_grammar= \"\"\"\n",
    "    S -> NP VP PUNCT | NP VP | PUNCT NP VP PUNCT\n",
    "    NP -> NUM N ADJ | N | NP ADJP | DET NP \n",
    "    VP -> VP NP | V | VP ADVP | VP SCONJ VP | AUX VP | VP PUNCT | AUX ADJP| AUX ADV \n",
    "    ADVP -> ADV \n",
    "    ADJP -> ADJ | ADJ ADJP\n",
    "    PP -> P NP\n",
    "    \"\"\" + spacy_to_nltk_grammar\n",
    "    print(\"French setup done\")\n",
    "    return nlp, sentences, base_grammar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree pipeline function\n",
    "<ol>\n",
    "    <li>Computes the pos tag of the sentence</li>\n",
    "    <li>Add the Tagged words to the grammar as Terminal</li>\n",
    "    <li>Create a parser with the specific grammar</li>\n",
    "    <li>Print the tree</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(nlp, sentences, base_grammar):\n",
    "    \"\"\"\n",
    "    Given spacy pos tagger, senteces and a language, this function prints the grammar tree of each sentence in sentences.\n",
    "    As first step it uses the pos tagger to estract the Terminals of that sentence.\n",
    "    Then it add the grammar rules with \"POS -> terminals\".\n",
    "    In the end generate a NLTK grammar that will be used for the parser to parse the sentence to get the tree.\n",
    "    \"\"\"\n",
    "    for sentence in sentences: \n",
    "        #pos tagging\n",
    "        sentence_pos = set()\n",
    "        grammar = {}\n",
    "        spacy_parsed_sent= nlp(sentence)\n",
    "        print(f\"{sentence}\\n\")\n",
    "        for token in spacy_parsed_sent:\n",
    "            print(f\"{token.text } -> {token.pos_}\")\n",
    "            sentence_pos.add(token.pos_)\n",
    "            if not token.pos_ in grammar:\n",
    "                grammar[token.pos_] = []\n",
    "            word = '\"' + token.text + '\"'\n",
    "            if word not in grammar[token.pos_]:\n",
    "                grammar[token.pos_].append(word)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #Grammar rules update\n",
    "        grammar_rules = base_grammar\n",
    "        for type in sentence_pos:  \n",
    "            appo_string = f\"{type} -> \"\n",
    "            index = len(grammar[type]) - 1\n",
    "            for word in grammar[type][0:index]:\n",
    "                appo_string+= \" {} |\".format(word)\n",
    "            appo_string+= \" {}\\n\".format(grammar[type][-1])\n",
    "            grammar_rules+= appo_string \n",
    "        \n",
    "        #Parser SetUp, and sentences parsing\n",
    "        nltk_grammar = nltk.CFG.fromstring(grammar_rules)\n",
    "        parser = nltk.ChartParser(nltk_grammar)\n",
    "        spacy_tokenized = list(map(lambda e:e.text,spacy_parsed_sent))\n",
    "        trees = list(parser.parse(spacy_tokenized))\n",
    "        if trees: \n",
    "            print(trees[0]) \n",
    "            print(trees[0].pretty_print()) \n",
    "        else: print(\"No tree found\")  \n",
    "\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and loading stuffs for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_sentence = input(\"Sentence Language [EN/DE/IT/FR]: \")\n",
    "#language_sentence = \"EN\"\n",
    "language_sentence = language_sentence.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian setup done\n",
      "Il gatto rosso corre velocemente.\n",
      "\n",
      "Il -> DET\n",
      "gatto -> NOUN\n",
      "rosso -> ADJ\n",
      "corre -> VERB\n",
      "velocemente -> ADV\n",
      ". -> PUNCT\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (NP (DET Il) (NP (N (NOUN gatto)))) (ADJP (ADJ rosso)))\n",
      "  (VP (VP (V (VERB corre))) (ADVP (ADV velocemente)))\n",
      "  (PUNCT .))\n",
      "                S                              \n",
      "           _____|___________________________    \n",
      "          NP               |                |  \n",
      "      ____|_____           |                |   \n",
      "     NP         |          VP               |  \n",
      "  ___|____      |      ____|_______         |   \n",
      " |        NP    |     VP           |        |  \n",
      " |        |     |     |            |        |   \n",
      " |        N    ADJP   V           ADVP      |  \n",
      " |        |     |     |            |        |   \n",
      "DET      NOUN  ADJ   VERB         ADV     PUNCT\n",
      " |        |     |     |            |        |   \n",
      " Il     gatto rosso corre     velocemente   .  \n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "Il gatto grigio è nero.\n",
      "\n",
      "Il -> DET\n",
      "gatto -> NOUN\n",
      "grigio -> ADJ\n",
      "è -> AUX\n",
      "nero -> ADJ\n",
      ". -> PUNCT\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (NP (DET Il) (NP (N (NOUN gatto)))) (ADJP (ADJ grigio)))\n",
      "  (VP (AUX è) (ADJP (ADJ nero)))\n",
      "  (PUNCT .))\n",
      "                S                      \n",
      "           _____|___________________    \n",
      "          NP              |         |  \n",
      "      ____|_____          |         |   \n",
      "     NP         |         |         |  \n",
      "  ___|____      |         |         |   \n",
      " |        NP    |         VP        |  \n",
      " |        |     |      ___|___      |   \n",
      " |        N    ADJP   |      ADJP   |  \n",
      " |        |     |     |       |     |   \n",
      "DET      NOUN  ADJ   AUX     ADJ  PUNCT\n",
      " |        |     |     |       |     |   \n",
      " Il     gatto grigio  è      nero   .  \n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "Il gatto sta correndo via\n",
      "\n",
      "Il -> DET\n",
      "gatto -> NOUN\n",
      "sta -> AUX\n",
      "correndo -> VERB\n",
      "via -> ADV\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (DET Il) (NP (N (NOUN gatto))))\n",
      "  (VP (VP (AUX sta) (VP (V (VERB correndo)))) (ADVP (ADV via))))\n",
      "               S                   \n",
      "      _________|_________           \n",
      "     |                   VP        \n",
      "     |              _____|______    \n",
      "     NP            VP           |  \n",
      "  ___|____      ___|_____       |   \n",
      " |        NP   |         VP     |  \n",
      " |        |    |         |      |   \n",
      " |        N    |         V     ADVP\n",
      " |        |    |         |      |   \n",
      "DET      NOUN AUX       VERB   ADV \n",
      " |        |    |         |      |   \n",
      " Il     gatto sta     correndo via \n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "Adoro i gatti.\n",
      "\n",
      "Adoro -> VERB\n",
      "i -> DET\n",
      "gatti -> NOUN\n",
      ". -> PUNCT\n",
      "\n",
      "\n",
      "No tree found\n",
      "\n",
      "\n",
      "\n",
      "I gatti piccoli sono fantastici.\n",
      "\n",
      "I -> DET\n",
      "gatti -> NOUN\n",
      "piccoli -> ADJ\n",
      "sono -> AUX\n",
      "fantastici -> ADJ\n",
      ". -> PUNCT\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (NP (DET I) (NP (N (NOUN gatti)))) (ADJP (ADJ piccoli)))\n",
      "  (VP (AUX sono) (ADJP (ADJ fantastici)))\n",
      "  (PUNCT .))\n",
      "                 S                             \n",
      "           ______|__________________________    \n",
      "          NP                |               |  \n",
      "      ____|______           |               |   \n",
      "     NP          |          |               |  \n",
      "  ___|____       |          |               |   \n",
      " |        NP     |          VP              |  \n",
      " |        |      |      ____|______         |   \n",
      " |        N     ADJP   |          ADJP      |  \n",
      " |        |      |     |           |        |   \n",
      "DET      NOUN   ADJ   AUX         ADJ     PUNCT\n",
      " |        |      |     |           |        |   \n",
      " I      gatti piccoli sono     fantastici   .  \n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n",
      "I gatti grassi sono fantastici.\n",
      "\n",
      "I -> DET\n",
      "gatti -> NOUN\n",
      "grassi -> ADJ\n",
      "sono -> AUX\n",
      "fantastici -> ADJ\n",
      ". -> PUNCT\n",
      "\n",
      "\n",
      "(S\n",
      "  (NP (NP (DET I) (NP (N (NOUN gatti)))) (ADJP (ADJ grassi)))\n",
      "  (VP (AUX sono) (ADJP (ADJ fantastici)))\n",
      "  (PUNCT .))\n",
      "                S                             \n",
      "           _____|__________________________    \n",
      "          NP               |               |  \n",
      "      ____|_____           |               |   \n",
      "     NP         |          |               |  \n",
      "  ___|____      |          |               |   \n",
      " |        NP    |          VP              |  \n",
      " |        |     |      ____|______         |   \n",
      " |        N    ADJP   |          ADJP      |  \n",
      " |        |     |     |           |        |   \n",
      "DET      NOUN  ADJ   AUX         ADJ     PUNCT\n",
      " |        |     |     |           |        |   \n",
      " I      gatti grassi sono     fantastici   .  \n",
      "\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if language_sentence == \"EN\": nlp, sentences, base_grammar = load_english(); generate_tree(nlp, sentences, base_grammar)\n",
    "elif language_sentence == \"DE\": nlp, sentences, base_grammar = load_german(); generate_tree(nlp, sentences, base_grammar)\n",
    "elif language_sentence == \"IT\": nlp, sentences, base_grammar = load_italian(); generate_tree(nlp, sentences, base_grammar)\n",
    "elif language_sentence == \"FR\": nlp, sentences, base_grammar = load_french(); generate_tree(nlp, sentences, base_grammar)\n",
    "else: print(\"language not valid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
